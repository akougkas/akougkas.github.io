<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | akougkas.io </title> <meta name="author" content="Anthony Kougkas"> <meta name="description" content="publications by categories in reversed chronological order."> <meta name="keywords" content="Data Management, HPC Storage, Distributed Systems, AI/ML"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/avatar_profile.png?aee8e1bd4fa75b6dd8d1e3f57b4b351f"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://akougkas.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> akougkas.io </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">more </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/blog/">blog</a> <a class="dropdown-item " href="/network/">network</a> <a class="dropdown-item " href="/repositories/">repositories</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order.</p> </header> <article> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div id="logan2023evaluation" class="col-sm-10"> <div class="title">An Evaluation of DAOS for Simulation and Deep Learning HPC Workloads</div> <div class="author"> Luke Logan , Jay Lofstead , Xian-He Sun, and <em>Anthony Kougkas</em> </div> <div class="periodical"> <em>In Proceedings of the 3rd Workshop on Challenges and Opportunities of Efficient and Performant Storage Systems</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="lee2023data" class="col-sm-10"> <div class="title">Data Flow Lifecycles for Optimizing Workflow Coordination</div> <div class="author"> Hyungro Lee , Luanzheng Guo , Meng Tang , Jesun Firoz , Nathan Tallent, <em>Anthony Kougkas</em> , and Xian-He Sun </div> <div class="periodical"> <em>In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="yildirim2023iomax" class="col-sm-10"> <div class="title">IOMax: Maximizing Out-of-Core I/O Analysis Performance on HPC Systems</div> <div class="author"> Izzet Yildirim , Hariharan Devarajan, <em>Anthony Kougkas</em> , Xian-He Sun , and Kathryn Mohror </div> <div class="periodical"> <em>In Proceedings of the SC’23 Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div id="devarajan2022stimulus" class="col-sm-10"> <div class="title">Stimulus: Accelerate Data Management for Scientific AI applications in HPC</div> <div class="author"> Hariharan Devarajan, <em>Anthony Kougkas</em> , Huihuo Zheng , Venkatram Vishwanath , and Xian-He Sun </div> <div class="periodical"> <em>In 2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="logan2022labstor" class="col-sm-10"> <div class="title">LabStor: A modular and extensible platform for developing high-performance, customized I/O stacks in userspace</div> <div class="author"> Luke Logan, Jaime Cernuda Garcia , Jay Lofstead , Xian–He Sun, and <em>Anthony Kougkas</em> </div> <div class="periodical"> <em>In SC22: International Conference for High Performance Computing, Networking, Storage and Analysis</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="bateman2022luxio" class="col-sm-10"> <div class="title">LuxIO: Intelligent Resource Provisioning and Auto-Configuration for Storage Services</div> <div class="author"> Keith Bateman , Neeraj Rajesh, Jaime Cernuda Garcia , Luke Logan , Jie Ye , Stephen Herbein, <em>Anthony Kougkas</em> , and Xian-He Sun </div> <div class="periodical"> <em>In 2022 IEEE 29th International Conference on High Performance Computing, Data, and Analytics (HiPC)</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div id="devarajan2021dlio" class="col-sm-10"> <div class="title">Dlio: A data-centric benchmark for scientific deep learning applications</div> <div class="author"> Hariharan Devarajan , Huihuo Zheng, <em>Anthony Kougkas</em> , Xian-He Sun , and Venkatram Vishwanath </div> <div class="periodical"> <em>In 2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)</em> , 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="rajesh2021apollo" class="col-sm-10"> <div class="title">Apollo: An ML-assisted real-time storage resource observer</div> <div class="author"> Neeraj Rajesh , Hariharan Devarajan, Jaime Cernuda Garcia , Keith Bateman , Luke Logan , Jie Ye, <em>Anthony Kougkas</em> , and Xian-He Sun </div> <div class="periodical"> <em>In Proceedings of the 30th International Symposium on High-Performance Parallel and Distributed Computing</em> , 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="logan2021pmemcpy" class="col-sm-10"> <div class="title">pMEMCPY: a simple, lightweight, and portable I/O library for storing data in persistent memory</div> <div class="author"> Luke Logan , Jay Lofstead, Scott Levy, Patrick Widener , Xian-He Sun, and <em>Anthony Kougkas</em> </div> <div class="periodical"> <em>In 2021 IEEE International Conference on Cluster Computing (CLUSTER)</em> , 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="cernuda2021hflow" class="col-sm-10"> <div class="title">Hflow: A dynamic and elastic multi-layered i/o forwarder</div> <div class="author"> Jaime Cernuda , Hariharan Devarajan , Luke Logan , Keith Bateman , Neeraj Rajesh , Jie Ye, <em>Anthony Kougkas</em> , and Xian-He Sun </div> <div class="periodical"> <em>In 2021 IEEE International Conference on Cluster Computing (CLUSTER)</em> , 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div id="kougkas2020acceleration" class="col-sm-10"> <div class="title">I/O Acceleration via Multi-Tiered Data Buffering and Prefetching</div> <div class="author"> <em>Anthony Kougkas</em> , Hariharan Devarajan , and Xian-He Sun </div> <div class="periodical"> <em>In JCST’20: International Journal of Computer Science and Technology</em> , Jan 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/article/10.1007/s11390-020-9781-1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/labios_jcst.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=hiNO0EEAAAAJ&amp;citation_for_view=hiNO0EEAAAAJ:Wp0gIr-vW9MC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-18-4285F4?logo=googlescholar&amp;labelColor=beige" alt="18 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Modern High-Performance Computing (HPC) systems are adding extra layers to the memory and storage hierarchy, named deep memory and storage hierarchy (DMSH), to increase I/O performance. New hardware technologies, such as NVMe and SSD, have been introduced in burst buffer installations to reduce the pressure for external storage and boost the burstiness of modern I/O systems. The DMSH has demonstrated its strength and potential in practice. However, each layer of DMSH is an independent heterogeneous system and data movement among more layers is significantly more complex even without considering heterogeneity. How to efficiently utilize the DMSH is a subject of research facing the HPC community. Further, accessing data with a high-throughput and low-latency is more imperative than ever. Data prefetching is a well-known technique for hiding read latency by requesting data before it is needed to move it from a high-latency medium (e.g., disk) to a low-latency one (e.g., main memory). However, existing solutions do not consider the new deep memory and storage hierarchy and also suffer from under-utilization of prefetching resources and unnecessary evictions. Additionally, existing approaches implement a client-pull model where understanding the application’s I/O behavior drives prefetching decisions. Moving towards exascale, where machines run multiple applications concurrently by accessing files in a workflow, a more data-centric approach resolves challenges such as cache pollution and redundancy. In this paper, we present the design and implementation of Hermes: a new, heterogeneous-aware, multi-tiered, dynamic, and distributed I/O buffering system. Hermes enables, manages, supervises, and, in some sense, extends I/O buffering to fully integrate into the DMSH. We introduce three novel data placement policies to efficiently utilize all layers and we present three novel techniques to perform memory, metadata, and communication management in hierarchical buffering systems. Additionally, we demonstrate the benefits of a truly hierarchical data prefetcher that adopts a server-push approach to data prefetching. Our evaluation shows that, in addition to automatic data movement through the hierarchy, Hermes can significantly accelerate I/O and outperforms by more than 2x state-of-the-art buffering platforms. Lastly, results show 10% to 35% performance gains over existing prefetchers and over 50% when compared to systems with no prefetching.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kougkas2020acceleration</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kougkas, Anthony and Devarajan, Hariharan and Sun, Xian-He}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{JCST'20: International Journal of Computer Science and Technology}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{I/O Acceleration via Multi-Tiered Data Buffering and Prefetching}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{35}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{92--120}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{I/O buffering, heterogeneous buffering, layered buffering, deep memory hierarchy, burst buffers, hierarchical data prefetching,data-centric architecture}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s11390-020-9781-1}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/article/10.1007/s11390-020-9781-1}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{Wp0gIr-vW9MC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="devarajan2020hfetch" class="col-sm-10"> <div class="title">Hfetch: Hierarchical data prefetching for scientific workflows in multi-tiered storage environments</div> <div class="author"> Hariharan Devarajan, <em>Anthony Kougkas</em> , and Xian-He Sun </div> <div class="periodical"> <em>In 2020 IEEE International Parallel and Distributed Processing Symposium (IPDPS)</em> , Jan 2020 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="devarajan2020hcompress" class="col-sm-10"> <div class="title">Hcompress: Hierarchical data compression for multi-tiered storage environments</div> <div class="author"> Hariharan Devarajan, <em>Anthony Kougkas</em> , Luke Logan , and Xian-He Sun </div> <div class="periodical"> <em>In 2020 IEEE International Parallel and Distributed Processing Symposium (IPDPS)</em> , Jan 2020 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kougkas2020bridging" class="col-sm-10"> <div class="title">Bridging Storage Semantics Using Data Labels and Asynchronous I/O</div> <div class="author"> <em>Anthony Kougkas</em> , Hariharan Devarajan , and Xian-He Sun </div> <div class="periodical"> <em>ACM Transactions on Storage (TOS)</em>, Jan 2020 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kougkas2020chronolog" class="col-sm-10"> <div class="title">ChronoLog: A Distributed Shared Tiered Log Store with Time-based Data Ordering</div> <div class="author"> <em>Anthony Kougkas</em> , Hariharan Devarajan , Keith Bateman , Jaime Cernuda , Neeraj Rajesh , and Xian-He Sun </div> <div class="periodical"> <em>In 36th International Conference on Massive Storage Systems and Technology (MSST 2020)</em> , Jan 2020 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="devarajan2020hcl" class="col-sm-10"> <div class="title">Hcl: Distributing parallel data structures in extreme scales</div> <div class="author"> Hariharan Devarajan, <em>Anthony Kougkas</em> , Keith Bateman , and Xian-He Sun </div> <div class="periodical"> <em>In 2020 IEEE International Conference on Cluster Computing (CLUSTER)</em> , Jan 2020 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="devarajan2020hreplica" class="col-sm-10"> <div class="title">Hreplica: a dynamic data replication engine with adaptive compression for multi-tiered storage</div> <div class="author"> Hariharan Devarajan, <em>Anthony Kougkas</em> , and Xian-He Sun </div> <div class="periodical"> <em>In 2020 IEEE International Conference on Big Data (Big Data)</em> , Jan 2020 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div id="devarajan2019intelligent" class="col-sm-10"> <div class="title">An intelligent, adaptive, and flexible data compression framework</div> <div class="author"> Hariharan Devarajan, <em>Anthony Kougkas</em> , and Xian-He Sun </div> <div class="periodical"> <em>In CCGRID’18: Proceedings of the 19th International Symposium on Cluster, Cloud and Grid Computing</em> , May 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/8752926" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/ares.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=hiNO0EEAAAAJ&amp;citation_for_view=hiNO0EEAAAAJ:_kc_bZDykSQC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-15-4285F4?logo=googlescholar&amp;labelColor=beige" alt="15 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>The data explosion phenomenon in modern applications causes tremendous stress on storage systems. Developers use data compression, a size-reduction technique, to address this issue. However, each compression library exhibits different strengths and weaknesses when considering the input data type and format. We present Ares, an intelligent, adaptive, and flexible compression framework which can dynamically choose a compression library for a given input data based on the type of the workload and provides an appropriate infrastructure to users to fine-tune the chosen library. Ares is a modular framework which unifies several compression libraries while allowing the addition of more compression libraries by the user. Ares is a unified compression engine that abstracts the complexity of using different compression libraries for each workload. Evaluation results show that under real-world applications, from both scientific and Cloud domains, Ares performed 2-6x faster than competitive solutions with a low cost of additional data analysis (i.e., overheads around 10%) and up to 10x faster against a baseline of no compression at all.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">devarajan2019intelligent</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Devarajan, Hariharan and Kougkas, Anthony and Sun, Xian-He}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{CCGRID'18: Proceedings of the 19th International Symposium on Cluster, Cloud and Grid Computing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An intelligent, adaptive, and flexible data compression framework}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{82--91}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Smart Intelligent Compression Framework, Data Compression Benchmark, Data Format, I/O Priority, Adaptive Flexible Data Compression}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/CCGRID.2019.00019}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/8752926}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{_kc_bZDykSQC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="kougkas2019labios" class="col-sm-10"> <div class="title">Labios: A distributed label-based i/o system</div> <div class="author"> <em>Anthony Kougkas</em> , Hariharan Devarajan , Jay Lofstead , and Xian-He Sun </div> <div class="periodical"> <em>In HPDC’19: Proceedings of the 28th International Symposium on High-Performance Parallel and Distributed Computing.</em> ║ <strong>Best Paper Award</strong> ║ , Jun 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Best Paper Award</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/abs/10.1145/3307681.3325405" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/labios.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=hiNO0EEAAAAJ&amp;citation_for_view=hiNO0EEAAAAJ:ULOm3_A8WrAC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-23-4285F4?logo=googlescholar&amp;labelColor=beige" alt="23 Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p><a href="https://www.hpdc.org/2019/awards/best-paper-award/" rel="external nofollow noopener" target="_blank">Karsten Schwan Best Paper Award</a> at HPDC’2019. Photo <a href="/assets/img/labios_award.jpg">here</a></p> </div> <div class="abstract hidden"> <p>In the era of data-intensive computing, large-scale applications, in both scientific and the BigData communities, demonstrate unique I/O requirements leading to a proliferation of different storage devices and software stacks, many of which have conflicting requirements. In this paper, we investigate how to support a wide variety of conflicting I/O workloads under a single storage system. We introduce the idea of a Label, a new data representation, and, we present LABIOS: a new, distributed, Label- based I/O system. LABIOS boosts I/O performance by up to 17x via asynchronous I/O, supports heterogeneous storage resources, offers storage elasticity, and promotes in-situ analytics via data provisioning. LABIOS demonstrates the effectiveness of storage bridging to support the convergence of HPC and BigData workloads on a single platform.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kougkas2019labios</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kougkas, Anthony and Devarajan, Hariharan and Lofstead, Jay and Sun, Xian-He}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{HPDC'19: Proceedings of the 28th International Symposium on High-Performance Parallel and Distributed Computing.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Labios: A distributed label-based i/o system}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{13--24}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3307681.3325405}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/abs/10.1145/3307681.3325405}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{ULOm3_A8WrAC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="feng2019niobe" class="col-sm-10"> <div class="title">NIOBE: An intelligent i/o bridging engine for complex and distributed workflows</div> <div class="author"> Kun Feng , Hariharan Devarajan, <em>Anthony Kougkas</em> , and Xian-He Sun </div> <div class="periodical"> <em>In BigData’19: Proceedings of the International Conference on Big Data</em> , Dec 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/9006363" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/niobe.com" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=hiNO0EEAAAAJ&amp;citation_for_view=hiNO0EEAAAAJ:4DMP91E08xMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-4-4285F4?logo=googlescholar&amp;labelColor=beige" alt="4 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>In the age of data-driven computing, integrating High Performance Computing(HPC) and Big Data(BD) environments may be the key to increasing productivity and to driving scientific discovery forward. Scientific workflows consist of diverse applications (i.e., HPC simulations and BD analysis) each with distinct representations of data that introduce a semantic barrier between the two environments. To solve scientific problems at scale, accessing semantically different data from different storage resources is the biggest unsolved challenge. In this work, we aim to address a critical question: ”How can we exploit the existing resources and efficiently provide transparent access to data from/to both environments”. We propose iNtelligent I/O Bridging Engine(NIOBE), a new data integration framework that enables integrated data access for scientific workflows with asynchronous I/O and data aggregation. NIOBE performs the data integration using available I/O resources, in contrast to existing optimizations that ignore the I/O nodes present on the data path. In NIOBE, data access is optimized to consider both the ongoing production and the consumption of the data in the future. Experimental results show that with NIOBE, an integrated scientific workflow can be accelerated by up to 10x when compared to a no-integration baseline and by up to 133% compared to other state-of-the-art integration solutions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">feng2019niobe</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Feng, Kun and Devarajan, Hariharan and Kougkas, Anthony and Sun, Xian-He}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{BigData'19: Proceedings of the International Conference on Big Data}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{NIOBE: An intelligent i/o bridging engine for complex and distributed workflows}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{493--502}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Data aggregation, Data integration, Data models, I/O Optimization, I/O Acceleration, API Connectors, I/O Integration}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/BigData47090.2019.9006363}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/9006363}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{4DMP91E08xMC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div id="kougkas2018hermes" class="col-sm-10"> <div class="title">Hermes: a heterogeneous-aware multi-tiered distributed I/O buffering system</div> <div class="author"> <em>Anthony Kougkas</em> , Hariharan Devarajan , and Xian-He Sun </div> <div class="periodical"> <em>In HPDC’18: Proceedings of the 27th International Symposium on High-Performance Parallel and Distributed Computing</em> , Jun 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/abs/10.1145/3208040.3208059" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/hermes.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=hiNO0EEAAAAJ&amp;citation_for_view=hiNO0EEAAAAJ:hqOjcs7Dif8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-89-4285F4?logo=googlescholar&amp;labelColor=beige" alt="89 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Modern High-Performance Computing (HPC) systems are adding extra layers to the memory and storage hierarchy named deep memory and storage hierarchy (DMSH), to increase I/O performance. New hardware technologies, such as NVMe and SSD, have been introduced in burst buffer installations to reduce the pressure for external storage and boost the burstiness of modern I/O systems. The DMSH has demonstrated its strength and potential in practice. However, each layer of DMSH is an independent heterogeneous system and data movement among more layers is significantly more complex even without considering heterogeneity. How to efficiently utilize the DMSH is a subject of research facing the HPC community. In this paper, we present the design and implementation of Hermes: a new, heterogeneous-aware, multi-tiered, dynamic, and distributed I/O buffering system. Hermes enables, manages, supervises, and, in some sense, extends I/O buffering to fully integrate into the DMSH. We introduce three novel data placement policies to efficiently utilize all layers and we present three novel techniques to perform memory, metadata, and communication management in hierarchical buffering systems. Our evaluation shows that, in addition to automatic data movement through the hierarchy, Hermes can significantly accelerate I/O and outperforms by more than 2x state-of-the-art buffering platforms.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kougkas2018hermes</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kougkas, Anthony and Devarajan, Hariharan and Sun, Xian-He}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{HPDC'18: Proceedings of the 27th International Symposium on High-Performance Parallel and Distributed Computing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hermes: a heterogeneous-aware multi-tiered distributed I/O buffering system}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{219--230}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3208040.3208059}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/abs/10.1145/3208040.3208059}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{hqOjcs7Dif8C}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="kougkas2018iris" class="col-sm-10"> <div class="title">Iris: I/o redirection via integrated storage</div> <div class="author"> <em>Anthony Kougkas</em> , Hariharan Devarajan , and Xian-He Sun </div> <div class="periodical"> <em>In ICS’18: Proceedings of the 2018 International Conference on Supercomputing</em> , Jun 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/abs/10.1145/3205289.3205322" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/iris.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=hiNO0EEAAAAJ&amp;citation_for_view=hiNO0EEAAAAJ:8k81kl-MbHgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-13-4285F4?logo=googlescholar&amp;labelColor=beige" alt="13 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>There is an ocean of available storage solutions in modern high-performance and distributed systems. These solutions consist of Parallel File Systems (PFS) for the more traditional high-performance computing (HPC) systems and of Object Stores for emerging cloud environments. More of ten than not, these storage solutions are tied to specific APIs and data models and thus, bind developers, applications, and entire computing facilities to using certain interfaces. Each storage system is designed and optimized for certain applications but does not perform well for others. Furthermore, modern applications have become more and more complex consisting of a collection of phases with different computation and I/O requirements. In this paper, we propose a unified storage access system, called IRIS (i.e., I/O Redirection via Integrated Storage). IRIS enables unified data access and seamlessly bridges the semantic gap between file systems and object stores. With IRIS, emerging High-Performance Data Analytics software has capable and diverse I/O support. IRIS can bring us closer to the convergence of HPC and Cloud environments by combining the best storage subsystems from both worlds. Experimental results show that IRIS can grant more than 7x improvement in performance than existing solutions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kougkas2018iris</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kougkas, Anthony and Devarajan, Hariharan and Sun, Xian-He}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICS'18: Proceedings of the 2018 International Conference on Supercomputing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Iris: I/o redirection via integrated storage}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{33--42}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3205289.3205322}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/abs/10.1145/3205289.3205322}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{8k81kl-MbHgC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="kougkas2018harmonia" class="col-sm-10"> <div class="title">Harmonia: An interference-aware dynamic I/O scheduler for shared non-volatile burst buffers</div> <div class="author"> <em>Anthony Kougkas</em> , Hariharan Devarajan , Xian-He Sun , and Jay Lofstead </div> <div class="periodical"> <em>In CLUSTER’18: Proceedings of the International Conference on Cluster Computing</em> , Sep 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/8514889" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/harmonia.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=hiNO0EEAAAAJ&amp;citation_for_view=hiNO0EEAAAAJ:3fE2CSJIrl8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-35-4285F4?logo=googlescholar&amp;labelColor=beige" alt="35 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Modern HPC systems employ burst buffer installations to reduce the peak I/O requirements for external storage and deal with the burstiness of I/O in modern scientific applications. These I/O buffering resources are shared between multiple applications that run concurrently. This leads to severe performance degradation due to contention, a phenomenon called cross-application I/O interference. In this paper, we first explore the negative effects of interference at the burst buffer layer and we present two new metrics that can quantitatively describe the slowdown applications experience due to interference. We introduce Harmonia, a new dynamic I/O scheduler that is aware of interference, adapts to the underlying system, implements a new 2-way decision-making process and employs several scheduling policies to maximize the system efficiency and applications’ performance. Our evaluation shows that Harmonia, through better I/O scheduling, can outperform by 3x existing state-of-the-art buffering management solutions and can lead to better resource utilization.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kougkas2018harmonia</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kougkas, Anthony and Devarajan, Hariharan and Sun, Xian-He and Lofstead, Jay}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{CLUSTER'18: Proceedings of the International Conference on Cluster Computing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Harmonia: An interference-aware dynamic I/O scheduler for shared non-volatile burst buffers}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{290--301}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Burst Buffers, I/O Scheduling, I/O Interference, Multi Tenancy, I/O Policies, Shared Buffers}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/8514889}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{3fE2CSJIrl8C}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="devarajan2018vidya" class="col-sm-10"> <div class="title">Vidya: Performing code-block I/O characterization for data access optimization</div> <div class="author"> Hariharan Devarajan, <em>Anthony Kougkas</em> , Prajwal Challa , and Xian-He Sun </div> <div class="periodical"> <em>In HiPC’18: Proceedings of the 25th International Conference on High Performance Computing</em> , Dec 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/8638067" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/vidya.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=hiNO0EEAAAAJ&amp;citation_for_view=hiNO0EEAAAAJ:Zph67rFs4hoC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-18-4285F4?logo=googlescholar&amp;labelColor=beige" alt="18 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Understanding, characterizing and tuning scientific applications’ I/O behavior is an increasingly complicated process in HPC systems. Existing tools use either offline profiling or online analysis to get insights into the applications’ I/O patterns. However, there is lack of a clear formula to characterize applications’ I/O. Moreover, these tools are application specific and do not account for multi-tenant systems. This paper presents Vidya, an I/O profiling framework which can predict application’s I/O intensity using a new formula called Code-Block I/O Characterization (CIOC). Using CIOC, developers and system architects can tune an application’s I/O behavior and better match the underlying storage system to maximize performance. Evaluation results show that Vidya can predict an application’s I/O intensity with a variance of 0.05%. Vidya can profile applications with a high accuracy of 98% while reducing profiling time by 9x. We further show how Vidya can optimize an application’s I/O time by 3.7x.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">devarajan2018vidya</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Devarajan, Hariharan and Kougkas, Anthony and Challa, Prajwal and Sun, Xian-He}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{HiPC'18: Proceedings of the 25th International Conference on High Performance Computing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Vidya: Performing code-block I/O characterization for data access optimization}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{255--264}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{I/O Systems, I/O profiling, I/O optimization, Source Code Characterization, High Performance Computing Systems}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/HiPC.2018.00036}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/8638067}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{Zph67rFs4hoC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"><li> <div class="row"> <div id="kougkas2017rethinking" class="col-sm-10"> <div class="title">Rethinking key–value store for parallel i/o optimization</div> <div class="author"> <em>Anthony Kougkas</em>, Hassan Eslami , Xian-He Sun, Rajeev Thakur, and William Gropp </div> <div class="periodical"> <em>In IJHPCA’17: The International Journal of High Performance Computing Applications</em> , 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://journals.sagepub.com/doi/abs/10.1177/1094342016677084" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/kvfs.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=hiNO0EEAAAAJ&amp;citation_for_view=hiNO0EEAAAAJ:eQOLeE2rZwMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-15-4285F4?logo=googlescholar&amp;labelColor=beige" alt="15 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Key–value stores are being widely used as the storage system for large-scale internet services and cloud storage systems. However, they are rarely used in HPC systems, where parallel file systems are the dominant storage solution. In this study, we examine the architecture differences and performance characteristics of parallel file systems and key–value stores. We propose using key–value stores to optimize overall Input/Output (I/O) performance, especially for workloads that parallel file systems cannot handle well, such as the cases with intense data synchronization or heavy metadata operations. We conducted experiments with several synthetic benchmarks, an I/O benchmark, and a real application. We modeled the performance of these two systems using collected data from our experiments, and we provide a predictive method to identify which system offers better I/O performance given a specific workload. The results show that we can optimize the I/O performance in HPC systems by utilizing key–value stores.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kougkas2017rethinking</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kougkas, Anthony and Eslami, Hassan and Sun, Xian-He and Thakur, Rajeev and Gropp, William}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IJHPCA'17: The International Journal of High Performance Computing Applications}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Rethinking key--value store for parallel i/o optimization}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{SAGE Publications Sage UK: London, England}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{31}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{335--356}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1177/109434201667}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://journals.sagepub.com/doi/abs/10.1177/1094342016677084}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{eQOLeE2rZwMC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"> <li> <div class="row"> <div id="bbio" class="col-sm-10"> <div class="title">Leveraging burst buffer coordination to prevent I/O interference</div> <div class="author"> <em>Anthony Kougkas</em> , Matthieu Dorier , Rob Latham , Rob Ross , and Xian-He Sun </div> <div class="periodical"> <em>In eScience’16: Proceedings of the 12th International Conference on e-Science</em> , Jun 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/7870922" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/bbio.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=hiNO0EEAAAAJ&amp;citation_for_view=hiNO0EEAAAAJ:W7OEmFMy1HYC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-52-4285F4?logo=googlescholar&amp;labelColor=beige" alt="52 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Concurrent accesses to the shared storage resources in current HPC machines lead to severe performance degradation caused by I/O contention. In this study, we identify some key challenges to efficiently handling interleaved data accesses, and we propose a system-wide solution to optimize global performance. We implemented and tested several I/O scheduling policies, including prioritizing specific applications by leveraging burst buffers to defer the conflicting accesses from another application and/or directing the requests to different storage servers inside the parallel file system infrastructure. The results show that we mitigate the negative effects of interference and optimize the performance up to 2x depending on the selected I/O policy.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">bbio</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kougkas, Anthony and Dorier, Matthieu and Latham, Rob and Ross, Rob and Sun, Xian-He}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{eScience'16: Proceedings of the 12th International Conference on e-Science}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Leveraging burst buffer coordination to prevent I/O interference}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{371-380}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{I/O Interference;Parallel File Systems;I/O Policies;I/O Staging;Burst Buffers}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/eScience.2016.7870922}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/7870922}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{W7OEmFMy1HYC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="kougkas2016towards" class="col-sm-10"> <div class="title">Towards energy efficient data management in HPC: the open ethernet drive approach</div> <div class="author"> <em>Anthony Kougkas</em>, Anthony Fleck , and Xian-He Sun </div> <div class="periodical"> <em>In PDSW-DISCS16: Proceedings of the 1st Joint International Workshop On Parallel Data Storage &amp; Data Intensive Scalable Computing Systems</em> , Nov 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/7836567" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/oed.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=hiNO0EEAAAAJ&amp;citation_for_view=hiNO0EEAAAAJ:YsMSGLbcyi4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-9-4285F4?logo=googlescholar&amp;labelColor=beige" alt="9 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>An Open Ethernet Drive (OED) is a new technology that encloses into a hard drive (HDD or SSD) a low-power processor, a fixed-size memory and an Ethernet card. In this study, we thoroughly evaluate the performance of such device and the energy requirements to operate it. The results show that first it is a viable solution to offload data-intensive computations on the OED while maintaining a reasonable performance, and second, the energy consumption savings from utilizing such technology are significant as it only consumes 10% of the power needed by a normal server node. We propose that by using OED devices as storage servers in HPC, we can run a reliable, scalable, cost and energy efficient storage solution.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kougkas2016towards</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kougkas, Anthony and Fleck, Anthony and Sun, Xian-He}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{PDSW-DISCS16: Proceedings of the 1st Joint International Workshop On Parallel Data Storage &amp; Data Intensive Scalable Computing Systems}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Towards energy efficient data management in HPC: the open ethernet drive approach}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{43-48}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Servers;Computer architecture;Random access memory;Benchmark testing;Performance evaluation;Energy consumption;Hardware;Open Ethernet Drives;Data Management;Data-Intensive Computing;Energy Efficiency;Benchmarking;Performance Evaluation}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/PDSW-DISCS.2016.012}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/7836567}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{YsMSGLbcyi4C}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2015</h2> <ol class="bibliography"> <li> <div class="row"> <div id="he2015heterogeneity" class="col-sm-10"> <div class="title">A Heterogeneity-Aware Region-Level Data Layout for Hybrid Parallel File Systems</div> <div class="author"> Shuibing He , Xian-He Sun , Yang Wang, <em>Anthony Kougkas</em> , and Adnan Haider </div> <div class="periodical"> <em>In ICPP’15: Proceedings of the 44th International Conference on Parallel Processing</em> , Dec 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/7349589" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/hadl.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=hiNO0EEAAAAJ&amp;citation_for_view=hiNO0EEAAAAJ:UeHWp8X0CEIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-21-4285F4?logo=googlescholar&amp;labelColor=beige" alt="21 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Parallel file systems (PFS) are commonly used in high-end computing systems. With the emergence of solid state drives (SSD), hybrid PFSs, which consist of both HDD and SSD servers, provide a practical I/O system solution for data-intensive applications. However, most existing PFS layout schemes are inefficient for hybrid PFSs due to their lack of awareness of the performance differences between heterogeneous servers and the workload changes between different parts of a file. This lack of recognition can result in severe I/O performance degradation. In this study, we propose a heterogeneity-aware region-level (HARL) data layout scheme to improve the data distribution of a hybrid PFS. HARL first divides a file into fine-grained, varying sized regions according to the changes of an application’s I/O workload, then chooses appropriate file stripe sizes on heterogeneous servers based on the server performance for each file region. Experimental results of representative benchmarks show that HARL can greatly improve the I/O system performance.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">he2015heterogeneity</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{He, Shuibing and Sun, Xian-He and Wang, Yang and Kougkas, Anthony and Haider, Adnan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICPP'15: Proceedings of the 44th International Conference on Parallel Processing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Heterogeneity-Aware Region-Level Data Layout for Hybrid Parallel File Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{340-349}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Servers;Layout;File systems;Benchmark testing;System performance;Computers;Solids;Parallel I/O System;Parallel File system;Solid State Drive;Data Layout}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICPP.2015.43}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/7349589}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{UeHWp8X0CEIC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="eslami2015efficient" class="col-sm-10"> <div class="title">Efficient disk-to-disk sorting: a case study in the decoupled execution paradigm</div> <div class="author"> Hassan Eslami, <em>Anthony Kougkas</em>, Maria Kotsifakou, Theodoros Kasampalis , Kun Feng, Yin Lu, William Gropp , Xian-He Sun, Yong Chen, and Rajeev Thakur </div> <div class="periodical"> <em>In DISCS’15: Proceedings of the International Workshop on Data-Intensive Scalable Computing</em> , Nov 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/abs/10.1145/2831244.2831249" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/d2dsort.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=hiNO0EEAAAAJ&amp;citation_for_view=hiNO0EEAAAAJ:IjCSPb-OGe4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-5-4285F4?logo=googlescholar&amp;labelColor=beige" alt="5 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Many applications foreseen for exascale era should process huge amount of data. However, the IO infrastructure of current supercomputing architecture cannot be generalized to deal with this amount of data due to the need for excessive data movement from storage layers to compute nodes leading to limited scalability. There has been extensive studies addressing this challenge. Decoupled Execution Paradigm (DEP) is an attractive solution due to its unique features such as available fast storage devices close to computational units and available programmable units close to file system. In this paper we study the effectiveness of DEP for a well-known data-intensive kernel, disk-to-disk (aka out-of-core) sorting. We propose an optimized algorithm that uses almost all features of DEP pushing the performance of sorting in HPC even further compared to other existing solutions. Advantages in our algorithm are gained by exploiting programming units close to parallel file system to achieve higher IO throughput, compressing data before sending it over network or to disk, storing intermediate results of computation close to compute nodes, and fully overlapping IO with computation. We also provide an analytical model for our proposed algorithm. Our algorithm achieves 30% better performance compared to the theoretically optimal sorting algorithm running on the same testbed but not designed to exploit the DEP architecture.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">eslami2015efficient</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Eslami, Hassan and Kougkas, Anthony and Kotsifakou, Maria and Kasampalis, Theodoros and Feng, Kun and Lu, Yin and Gropp, William and Sun, Xian-He and Chen, Yong and Thakur, Rajeev}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{DISCS'15: Proceedings of the International Workshop on Data-Intensive Scalable Computing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Efficient disk-to-disk sorting: a case study in the decoupled execution paradigm}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--8}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/2831244.2831249}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/abs/10.1145/2831244.2831249}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{IjCSPb-OGe4C}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0 d-flex justify-content-between"> <div class="left-footer" style="font-size: 0.7rem;"> © Copyright 2024 Anthony Kougkas. </div> <div class="middle-footer" style="flex: 1.2;"> <div class="contact-icons"> <a href="mailto:%61.%6B%6F%75%67%6B%61%73@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=hiNO0EEAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://grc.iit.edu/" title="Work" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-briefcase"></i></a> <a href="https://orcid.org/0000-0003-3943-663X" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://github.com/grc-iit" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/anthonykougkas" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/kougkas" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> </div> <div class="right-footer" style="font-size: 0.7rem;"> Last updated: July 01, 2024. </div> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?06cae41083477f121be8cd9797ad8e2f"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-home",title:"home",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-teaching",title:"teaching",description:"Materials for courses you taught. Replace this text with your description.",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"nav-cv",title:"cv",description:"This is a description of the page. You can modify it in '_pages/cv.md'. You can also change or remove the top pdf download button.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"dropdown-blog",title:"blog",description:"",section:"Dropdown",handler:()=>{window.location.href="/blog/"}},{id:"dropdown-network",title:"network",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-repositories",title:"repositories",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-github-metadata",title:"a post with github metadata",description:"a quick run down on accessing github metadata.",section:"Posts",handler:()=>{window.location.href="/blog/2020/github-metadata/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march & april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"projects-hermes",title:"Hermes",description:"Heterogeneous-Aware Multi-Tiered Distributed I/O Buffering System",section:"Projects",handler:()=>{window.location.href="/projects/1_hermes/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%61.%6B%6F%75%67%6B%61%73@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0003-3943-663X","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=hiNO0EEAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/grc-iit","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/anthonykougkas","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/kougkas","_blank")}},{id:"socials-work",title:"Work",section:"Socials",handler:()=>{window.open("https://grc.iit.edu/","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>